{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d924968",
   "metadata": {},
   "source": [
    "# 1. Setup Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e333d4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.34.69 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \"datasets[s3]==2.18.0\" \"sagemaker>=2.190.0\" \"huggingface_hub[cli]\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776bb2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\KIIT\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ee7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\KIIT\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name SageMakerUser to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::187605677219:role/sagemaker_execution_role\n",
      "sagemaker bucket: sagemaker-us-east-1-187605677219\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    \n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73961262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\kiit\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/95/fc/661a7f06e8b7d48fcbd3f55423b7ff1ac3ce59526f146fda87a1e1788ee4/datasets-2.18.0-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.19.4 (from datasets)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/47/8f/cf6683de320cf3873850ba48b7383db96958fe435b8e227db92119f6d867/huggingface_hub-0.21.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/3d/c8/c3342c97848896df5d78d18abd94c558e457a4f02feec99a79989d8c30e0/huggingface_hub-0.21.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/15/95/614f1a310e333e9bbf338bcc3c9378aa4c5ae7978b8621c934e27ce6befc/huggingface_hub-0.21.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/76/4d/8def98a3925c1e3a1b26eebdcf21ebc25e997b9ce85fd1c88290104b9ae5/huggingface_hub-0.21.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.21.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/28/03/7d3c7153113ec59cfb31e3b8ee773f5f420a0dd7d26d40442542b96675c3/huggingface_hub-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/3d/0a/aed3253a9ce63d9c90829b1d36bc44ad966499ff4f5827309099c8c9184b/huggingface_hub-0.20.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/a0/0a/02ac0ae1047d97769003ff4fb8e6717024f3f174a5d13257415aa09e13d9/huggingface_hub-0.20.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/69/03/46f112e2e415926bc7bdac2f5366572de0c28cb88051537b25a586b5d881/huggingface_hub-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.4 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting fsspec[http]<=2024.2.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2024.2.0,>=2023.1.0 from https://files.pythonhosted.org/packages/ad/30/2281c062222dc39328843bd1ddd30ff3005ef8e30b2fd09c4d2792766061/fsspec-2024.2.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiit\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Installing collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.12.0\n",
      "    Uninstalling datasets-2.12.0:\n",
      "      Successfully uninstalled datasets-2.12.0\n",
      "Successfully installed datasets-2.18.0 fsspec-2024.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ffc1e2",
   "metadata": {},
   "source": [
    "# 2. Create and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30550049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed17475cdfa44d289532aa6055dd10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 831k/831k [00:02<00:00, 344kB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126k/126k [00:01<00:00, 63.8kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbcfeb1d6ee44728dfc01e956c2238b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cde9227c1c24ea69188b2c31e7378d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f8a557460a4b258ea2e0719142b702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\ncollege_3', 'role': 'system'}, {'content': 'Find the last name of female (sex is F) students in the descending order of age.', 'role': 'user'}, {'content': 'SELECT LName FROM STUDENT WHERE Sex  =  \"F\" ORDER BY Age DESC', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "system_message = \"\"\"You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\n",
    "SCHEMA:\n",
    "{schema}\"\"\"\n",
    "\n",
    "def create_conversation(sample):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message.format(schema=sample[\"db_id\"])},\n",
    "      {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "      {\"role\": \"assistant\", \"content\": sample[\"query\"]}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"spider\", split=\"train\")\n",
    "dataset = dataset.shuffle().select(range(7000))\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features,batched=False)\n",
    "# split dataset into 10,000 training samples and 2,500 test samples\n",
    "dataset = dataset.train_test_split(test_size=1400/7000)\n",
    "\n",
    "print(dataset[\"train\"][345][\"messages\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3616d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\fsspec\\registry.py:273: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aed82abe5e4596a5936b0c3d5a69d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42040e6984f04a3695845075e26e1432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-187605677219/datasets/text-to-sql/train_dataset.json\n",
      "https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-187605677219/?region=us-east-1&prefix=datasets/text-to-sql/\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "training_input_path = f's3://{sess.default_bucket()}/datasets/text-to-sql'\n",
    "\n",
    "# save datasets to s3\n",
    "dataset[\"train\"].to_json(f\"{training_input_path}/train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(f\"{training_input_path}/test_dataset.json\", orient=\"records\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(f\"{training_input_path}/train_dataset.json\")\n",
    "print(f\"https://s3.console.aws.amazon.com/s3/buckets/{sess.default_bucket()}/?region={sess.boto_region_name}&prefix={training_input_path.split('/', 3)[-1]}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abbfc1",
   "metadata": {},
   "source": [
    "# 3. Fine-tune LLM using trl on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27eb247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "  ### SCRIPT PARAMETERS ###\n",
    "  'dataset_path': '/opt/ml/input/data/training/train_dataset.json', # path where sagemaker will save training dataset\n",
    "  'model_id': \"codellama/CodeLlama-7b-hf\",           # or `mistralai/Mistral-7B-v0.1`\n",
    "  'max_seq_len': 3072,                               # max sequence length for model and packing of the dataset\n",
    "  'use_qlora': True,                                 # use QLoRA model\n",
    "  ### TRAINING PARAMETERS ###\n",
    "  'num_train_epochs': 3,                             # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                  # batch size per device during training\n",
    "  'gradient_accumulation_steps': 4,                  # number of steps before performing a backward/update pass\n",
    "  'gradient_checkpointing': True,                    # use gradient checkpointing to save memory\n",
    "  'optim': \"adamw_torch_fused\",                      # use fused adamw optimizer\n",
    "  'logging_steps': 10,                               # log every 10 steps\n",
    "  'save_strategy': \"epoch\",                          # save checkpoint every epoch\n",
    "  'learning_rate': 2e-4,                             # learning rate, based on QLoRA paper\n",
    "  'bf16': True,                                      # use bfloat16 precision\n",
    "  'tf32': True,                                      # use tf32 precision\n",
    "  'max_grad_norm': 0.3,                              # max gradient norm based on QLoRA paper\n",
    "  'warmup_ratio': 0.03,                              # warmup ratio based on QLoRA paper\n",
    "  'lr_scheduler_type': \"constant\",                   # use constant learning rate scheduler\n",
    "  'report_to': \"tensorboard\",                        # report metrics to tensorboard\n",
    "  'output_dir': '/tmp/tun',                          # Temporary output directory for model checkpoints\n",
    "  'merge_adapters': True,                            # merge LoRA adapters into model for easier deployment\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba87d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'codellama-7b-hf-text-to-sql-exp1'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_sft.py',    # train script\n",
    "    source_dir           = 'C:/Users/KIIT/Desktop/Cloud Computing Lab/SageMaker/llm-sagemaker-sample-main/scripts/trl',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost\n",
    "    environment          = {\n",
    "                            \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "                            \"HF_TOKEN\": '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' # huggingface token to access gated models, e.g. llama 2\n",
    "                            },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b887076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-29 17:35:36 Starting - Starting the training job\n",
      "2024-03-29 17:35:36 Pending - Training job waiting for capacity......\n",
      "2024-03-29 17:36:24 Pending - Preparing the instances for training...\n",
      "2024-03-29 17:37:15 Downloading - Downloading the training image...............\n",
      "2024-03-29 17:40:11 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-29 17:40:48,073 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-29 17:40:48,091 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-29 17:40:48,101 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-29 17:40:48,102 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-29 17:40:49,569 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.38.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.7/130.7 kB 7.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.18.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.27.2 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes==0.42.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.42.0)\u001b[0m\n",
      "\u001b[34mCollecting trl==0.7.11 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.7.11-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft==0.8.2 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn==2.5.6 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.6.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 48.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (4.66.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (15.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r requirements.txt (line 2)) (2023.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 5)) (1.11.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11->-r requirements.txt (line 6)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (13.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (1.6.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (2.16.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.1.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 89.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 40.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 34.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading trl-0.7.11-py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 24.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.8.2-py3-none-any.whl (183 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 23.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=120352136 sha256=63ab5a3883b67719671e154beb91522e2901cbe4af0c5e031306a06a85df0be5\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn, accelerate, transformers, datasets, trl, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 2.3.6\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-2.3.6:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-2.3.6\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.25.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.25.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.25.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.36.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.36.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.36.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.15.0\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.15.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.15.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: trl\u001b[0m\n",
      "\u001b[34mFound existing installation: trl 0.7.4\u001b[0m\n",
      "\u001b[34mUninstalling trl-0.7.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled trl-0.7.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: peft\u001b[0m\n",
      "\u001b[34mFound existing installation: peft 0.7.1\u001b[0m\n",
      "\u001b[34mUninstalling peft-0.7.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled peft-0.7.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.27.2 datasets-2.18.0 flash-attn-2.5.6 peft-0.8.2 transformers-4.38.2 trl-0.7.11\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,419 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,419 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,464 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,499 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,534 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,545 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training/train_dataset.json\",\n",
      "        \"gradient_accumulation_steps\": 4,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"constant\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"max_seq_len\": 3072,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"codellama/CodeLlama-7b-hf\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"optim\": \"adamw_torch_fused\",\n",
      "        \"output_dir\": \"/tmp/tun\",\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"report_to\": \"tensorboard\",\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_qlora\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-187605677219/codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_sft\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_sft.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"codellama/CodeLlama-7b-hf\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_sft.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_sft\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-187605677219/codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"codellama/CodeLlama-7b-hf\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-187605677219/codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810/source/sourcedir.tar.gz\",\"module_name\":\"run_sft\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_sft.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training/train_dataset.json\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"constant\",\"--max_grad_norm\",\"0.3\",\"--max_seq_len\",\"3072\",\"--merge_adapters\",\"True\",\"--model_id\",\"codellama/CodeLlama-7b-hf\",\"--num_train_epochs\",\"3\",\"--optim\",\"adamw_torch_fused\",\"--output_dir\",\"/tmp/tun\",\"--per_device_train_batch_size\",\"1\",\"--report_to\",\"tensorboard\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_qlora\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training/train_dataset.json\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=constant\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LEN=3072\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=codellama/CodeLlama-7b-hf\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIM=adamw_torch_fused\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/tun\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_REPORT_TO=tensorboard\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_QLORA=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_sft.py --bf16 True --dataset_path /opt/ml/input/data/training/train_dataset.json --gradient_accumulation_steps 4 --gradient_checkpointing True --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type constant --max_grad_norm 0.3 --max_seq_len 3072 --merge_adapters True --model_id codellama/CodeLlama-7b-hf --num_train_epochs 3 --optim adamw_torch_fused --output_dir /tmp/tun --per_device_train_batch_size 1 --report_to tensorboard --save_strategy epoch --tf32 True --use_qlora True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,546 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-03-29 17:41:08,547 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 5600 examples [00:00, 597357.64 examples/s]\u001b[0m\n",
      "\u001b[34mUsing QLoRA\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/637 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 637/637 [00:00<00:00, 6.92MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 163MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 52.4M/9.98G [00:00<00:20, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 105M/9.98G [00:00<00:25, 384MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 157M/9.98G [00:00<00:23, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 210M/9.98G [00:00<00:22, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 262M/9.98G [00:00<00:21, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 315M/9.98G [00:00<00:22, 425MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 367M/9.98G [00:00<00:21, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 419M/9.98G [00:00<00:21, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 472M/9.98G [00:01<00:22, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 524M/9.98G [00:01<00:23, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 577M/9.98G [00:01<00:22, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▋         | 629M/9.98G [00:01<00:23, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 682M/9.98G [00:01<00:22, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 734M/9.98G [00:01<00:22, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 786M/9.98G [00:01<00:21, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 839M/9.98G [00:02<00:22, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 881M/9.98G [00:02<00:23, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 933M/9.98G [00:02<00:22, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 986M/9.98G [00:02<00:21, 425MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.04G/9.98G [00:02<00:21, 419MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.09G/9.98G [00:02<00:20, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.14G/9.98G [00:02<00:21, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:02<00:21, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:02<00:20, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.29G/9.98G [00:03<00:20, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.34G/9.98G [00:03<00:21, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.38G/9.98G [00:03<00:21, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.44G/9.98G [00:03<00:20, 414MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.49G/9.98G [00:03<00:19, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.54G/9.98G [00:03<00:19, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.59G/9.98G [00:03<00:18, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.65G/9.98G [00:03<00:18, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.70G/9.98G [00:04<00:17, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.75G/9.98G [00:04<00:18, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.80G/9.98G [00:04<00:19, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▊        | 1.86G/9.98G [00:04<00:18, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.91G/9.98G [00:04<00:19, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.96G/9.98G [00:04<00:20, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.00G/9.98G [00:04<00:19, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.04G/9.98G [00:04<00:19, 406MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.10G/9.98G [00:04<00:18, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.15G/9.98G [00:05<00:19, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.20G/9.98G [00:05<00:18, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.25G/9.98G [00:05<00:17, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.31G/9.98G [00:05<00:18, 422MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.36G/9.98G [00:05<00:17, 425MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.41G/9.98G [00:05<00:17, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.46G/9.98G [00:05<00:17, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.52G/9.98G [00:05<00:18, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.57G/9.98G [00:06<00:17, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▋       | 2.62G/9.98G [00:06<00:16, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.67G/9.98G [00:06<00:18, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.72G/9.98G [00:06<00:19, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.77G/9.98G [00:06<00:18, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.82G/9.98G [00:06<00:17, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.87G/9.98G [00:06<00:17, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.92G/9.98G [00:06<00:17, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.96G/9.98G [00:07<00:18, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.00G/9.98G [00:07<00:18, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.04G/9.98G [00:07<00:18, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.09G/9.98G [00:07<00:17, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███▏      | 3.14G/9.98G [00:07<00:18, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.19G/9.98G [00:07<00:16, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.24G/9.98G [00:07<00:15, 425MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.29G/9.98G [00:07<00:16, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.34G/9.98G [00:08<00:15, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.40G/9.98G [00:08<00:15, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.45G/9.98G [00:08<00:15, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.50G/9.98G [00:08<00:16, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.55G/9.98G [00:08<00:15, 414MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.61G/9.98G [00:08<00:15, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.66G/9.98G [00:08<00:15, 419MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.72G/9.98G [00:08<00:14, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.77G/9.98G [00:09<00:13, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.83G/9.98G [00:09<00:13, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.88G/9.98G [00:09<00:13, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.93G/9.98G [00:09<00:13, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.98G/9.98G [00:09<00:13, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 4.04G/9.98G [00:09<00:13, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.09G/9.98G [00:09<00:13, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.14G/9.98G [00:09<00:13, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.19G/9.98G [00:09<00:12, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.25G/9.98G [00:10<00:12, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.30G/9.98G [00:10<00:11, 477MB/s]#033[A\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.35G/9.98G [00:10<00:11, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.40G/9.98G [00:10<00:11, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [00:10<00:11, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.51G/9.98G [00:10<00:11, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.57G/9.98G [00:10<00:11, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▋     | 4.62G/9.98G [00:10<00:12, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.68G/9.98G [00:11<00:12, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.73G/9.98G [00:11<00:11, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.78G/9.98G [00:11<00:11, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.83G/9.98G [00:11<00:11, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.89G/9.98G [00:11<00:11, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.94G/9.98G [00:11<00:17, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.98G/9.98G [00:12<00:18, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 5.02G/9.98G [00:12<00:17, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.08G/9.98G [00:12<00:15, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████▏    | 5.13G/9.98G [00:12<00:13, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [00:12<00:13, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.22G/9.98G [00:12<00:11, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [00:12<00:11, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.34G/9.98G [00:12<00:10, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.39G/9.98G [00:12<00:10, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.44G/9.98G [00:13<00:09, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.49G/9.98G [00:13<00:10, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.55G/9.98G [00:13<00:10, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.60G/9.98G [00:13<00:10, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.65G/9.98G [00:13<00:09, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.70G/9.98G [00:13<00:10, 403MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.75G/9.98G [00:13<00:13, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.79G/9.98G [00:14<00:12, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▊    | 5.84G/9.98G [00:14<00:11, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.89G/9.98G [00:14<00:10, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.95G/9.98G [00:14<00:10, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 6.00G/9.98G [00:14<00:09, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.05G/9.98G [00:14<00:09, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.09G/9.98G [00:14<00:09, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.13G/9.98G [00:14<00:09, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.19G/9.98G [00:15<00:09, 412MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.24G/9.98G [00:15<00:08, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.29G/9.98G [00:15<00:08, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [00:15<00:10, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [00:15<00:14, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.42G/9.98G [00:15<00:16, 220MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.45G/9.98G [00:16<00:17, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [00:16<00:17, 200MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.51G/9.98G [00:16<00:17, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.53G/9.98G [00:16<00:17, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.56G/9.98G [00:16<00:17, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [00:16<00:16, 200MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [00:17<00:16, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [00:17<00:16, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [00:17<00:16, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [00:17<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.75G/9.98G [00:17<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.78G/9.98G [00:17<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.82G/9.98G [00:17<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.85G/9.98G [00:18<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.88G/9.98G [00:18<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.91G/9.98G [00:18<00:14, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.93G/9.98G [00:18<00:14, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.96G/9.98G [00:18<00:14, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.99G/9.98G [00:18<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 7.03G/9.98G [00:18<00:14, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.05G/9.98G [00:19<00:14, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.98G [00:19<00:14, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.10G/9.98G [00:19<00:14, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [00:19<00:14, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [00:19<00:13, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.19G/9.98G [00:19<00:13, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.22G/9.98G [00:19<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.26G/9.98G [00:20<00:12, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [00:20<00:12, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.31G/9.98G [00:20<00:12, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.33G/9.98G [00:20<00:12, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [00:20<00:12, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [00:20<00:12, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.41G/9.98G [00:20<00:12, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [00:21<00:12, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.47G/9.98G [00:21<00:12, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.50G/9.98G [00:21<00:11, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.53G/9.98G [00:21<00:11, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.55G/9.98G [00:21<00:11, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [00:21<00:11, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.59G/9.98G [00:21<00:11, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.61G/9.98G [00:22<00:17, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.64G/9.98G [00:22<00:13, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [00:22<00:09, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.73G/9.98G [00:22<00:09, 232MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [00:22<00:09, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [00:22<00:10, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.82G/9.98G [00:22<00:10, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▊  | 7.85G/9.98G [00:23<00:10, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.89G/9.98G [00:23<00:10, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [00:23<00:10, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.94G/9.98G [00:23<00:10, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.96G/9.98G [00:23<00:11, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.98G/9.98G [00:23<00:10, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 8.00G/9.98G [00:23<00:10, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 8.02G/9.98G [00:23<00:10, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.98G [00:24<00:10, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.06G/9.98G [00:24<00:10, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.08G/9.98G [00:24<00:10, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.11G/9.98G [00:24<00:10, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████▏ | 8.13G/9.98G [00:24<00:10, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.98G [00:24<00:09, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [00:24<00:10, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.19G/9.98G [00:24<00:09, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.21G/9.98G [00:24<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.23G/9.98G [00:25<00:09, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.25G/9.98G [00:25<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.98G [00:25<00:08, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.29G/9.98G [00:25<00:08, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.32G/9.98G [00:25<00:08, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.34G/9.98G [00:25<00:08, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.36G/9.98G [00:25<00:08, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.98G [00:25<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [00:26<00:08, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.43G/9.98G [00:26<00:08, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.45G/9.98G [00:26<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [00:26<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.49G/9.98G [00:26<00:07, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.51G/9.98G [00:26<00:08, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [00:26<00:07, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.56G/9.98G [00:26<00:08, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.58G/9.98G [00:26<00:07, 176MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [00:27<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [00:27<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.98G [00:27<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.66G/9.98G [00:27<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.68G/9.98G [00:27<00:07, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.70G/9.98G [00:27<00:07, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.72G/9.98G [00:27<00:06, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.75G/9.98G [00:27<00:06, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.77G/9.98G [00:28<00:06, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.79G/9.98G [00:28<00:06, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.81G/9.98G [00:28<00:06, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.83G/9.98G [00:28<00:06, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▊ | 8.85G/9.98G [00:28<00:06, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.87G/9.98G [00:28<00:06, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.89G/9.98G [00:28<00:06, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.91G/9.98G [00:28<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.93G/9.98G [00:28<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.95G/9.98G [00:29<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.98G/9.98G [00:29<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 9.00G/9.98G [00:29<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 9.02G/9.98G [00:29<00:05, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.04G/9.98G [00:29<00:05, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.06G/9.98G [00:29<00:05, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.08G/9.98G [00:29<00:05, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.11G/9.98G [00:30<00:04, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.13G/9.98G [00:30<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.15G/9.98G [00:30<00:04, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.18G/9.98G [00:30<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.20G/9.98G [00:30<00:04, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.22G/9.98G [00:30<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.24G/9.98G [00:30<00:04, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.26G/9.98G [00:30<00:04, 150MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.30G/9.98G [00:31<00:03, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.32G/9.98G [00:31<00:03, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.34G/9.98G [00:31<00:03, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.36G/9.98G [00:31<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.38G/9.98G [00:31<00:03, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.41G/9.98G [00:31<00:03, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [00:31<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.45G/9.98G [00:31<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.47G/9.98G [00:32<00:04, 125MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.51G/9.98G [00:32<00:02, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.54G/9.98G [00:32<00:02, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.57G/9.98G [00:32<00:02, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [00:32<00:02, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.62G/9.98G [00:32<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.64G/9.98G [00:33<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.98G [00:33<00:01, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.68G/9.98G [00:33<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.70G/9.98G [00:33<00:01, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.72G/9.98G [00:33<00:01, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.98G [00:33<00:01, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.76G/9.98G [00:33<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.78G/9.98G [00:33<00:01, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.80G/9.98G [00:34<00:01, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.83G/9.98G [00:34<00:00, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▊| 9.85G/9.98G [00:34<00:00, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.87G/9.98G [00:34<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.89G/9.98G [00:34<00:00, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.91G/9.98G [00:34<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.93G/9.98G [00:34<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.95G/9.98G [00:34<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.97G/9.98G [00:35<00:00, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:35<00:00, 283MB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:35<00:35, 35.27s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 41.9M/3.50G [00:00<00:09, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 83.9M/3.50G [00:00<00:16, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 115M/3.50G [00:00<00:17, 190MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▍         | 147M/3.50G [00:00<00:18, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▍         | 168M/3.50G [00:00<00:18, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▌         | 189M/3.50G [00:00<00:18, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 210M/3.50G [00:01<00:18, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 231M/3.50G [00:01<00:19, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 252M/3.50G [00:01<00:19, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 273M/3.50G [00:01<00:20, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▊         | 304M/3.50G [00:01<00:17, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 325M/3.50G [00:01<00:18, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 346M/3.50G [00:01<00:18, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 367M/3.50G [00:02<00:18, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 388M/3.50G [00:02<00:17, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 409M/3.50G [00:02<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 430M/3.50G [00:02<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 451M/3.50G [00:02<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 472M/3.50G [00:02<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 493M/3.50G [00:02<00:17, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 514M/3.50G [00:02<00:17, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 535M/3.50G [00:02<00:16, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 556M/3.50G [00:03<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▋        | 577M/3.50G [00:03<00:16, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 598M/3.50G [00:03<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 619M/3.50G [00:03<00:16, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▊        | 650M/3.50G [00:03<00:14, 192MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 682M/3.50G [00:03<00:13, 213MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|██        | 713M/3.50G [00:03<00:12, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██▏       | 744M/3.50G [00:03<00:11, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 776M/3.50G [00:04<00:11, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 807M/3.50G [00:04<00:10, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 839M/3.50G [00:04<00:10, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▍       | 870M/3.50G [00:04<00:10, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 902M/3.50G [00:04<00:09, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 933M/3.50G [00:04<00:09, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 965M/3.50G [00:04<00:09, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 996M/3.50G [00:04<00:09, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.03G/3.50G [00:05<00:09, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.06G/3.50G [00:05<00:09, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.09G/3.50G [00:05<00:09, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.12G/3.50G [00:05<00:09, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.15G/3.50G [00:05<00:09, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.18G/3.50G [00:05<00:08, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▍      | 1.22G/3.50G [00:05<00:08, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.25G/3.50G [00:05<00:08, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.28G/3.50G [00:06<00:08, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.31G/3.50G [00:06<00:08, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.34G/3.50G [00:06<00:08, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.37G/3.50G [00:06<00:08, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.41G/3.50G [00:06<00:09, 228MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.44G/3.50G [00:06<00:10, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.46G/3.50G [00:06<00:10, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [00:07<00:15, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▎     | 1.53G/3.50G [00:07<00:09, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 1.56G/3.50G [00:07<00:09, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 1.59G/3.50G [00:07<00:10, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▋     | 1.63G/3.50G [00:07<00:11, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 1.65G/3.50G [00:08<00:11, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [00:08<00:10, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 1.69G/3.50G [00:08<00:10, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 1.71G/3.50G [00:08<00:10, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [00:08<00:10, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 1.75G/3.50G [00:08<00:10, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 1.77G/3.50G [00:08<00:10, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 1.79G/3.50G [00:08<00:10, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 1.81G/3.50G [00:09<00:10, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 1.84G/3.50G [00:09<00:09, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 1.86G/3.50G [00:09<00:10, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▎    | 1.88G/3.50G [00:09<00:09, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 1.90G/3.50G [00:09<00:10, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 1.92G/3.50G [00:09<00:09, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 1.94G/3.50G [00:09<00:09, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 1.96G/3.50G [00:09<00:09, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 1.98G/3.50G [00:10<00:09, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.00G/3.50G [00:10<00:09, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.02G/3.50G [00:10<00:09, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.04G/3.50G [00:10<00:09, 153MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.07G/3.50G [00:10<00:08, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.09G/3.50G [00:10<00:09, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.12G/3.50G [00:10<00:08, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.14G/3.50G [00:11<00:08, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.16G/3.50G [00:11<00:08, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.18G/3.50G [00:11<00:08, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [00:11<00:07, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▎   | 2.22G/3.50G [00:11<00:07, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.24G/3.50G [00:11<00:07, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [00:11<00:07, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 2.29G/3.50G [00:11<00:07, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 2.31G/3.50G [00:12<00:07, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [00:12<00:07, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 2.35G/3.50G [00:12<00:07, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 2.37G/3.50G [00:12<00:06, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [00:12<00:06, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 2.41G/3.50G [00:12<00:06, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 2.43G/3.50G [00:12<00:06, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|███████   | 2.45G/3.50G [00:13<00:06, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 2.47G/3.50G [00:13<00:06, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████▏  | 2.50G/3.50G [00:13<00:06, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [00:13<00:06, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 2.54G/3.50G [00:13<00:05, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 2.56G/3.50G [00:13<00:05, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [00:13<00:05, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 2.60G/3.50G [00:13<00:05, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 2.62G/3.50G [00:14<00:05, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [00:14<00:05, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 2.66G/3.50G [00:14<00:05, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 2.68G/3.50G [00:14<00:05, 157MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [00:14<00:05, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 2.73G/3.50G [00:14<00:05, 153MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 2.75G/3.50G [00:14<00:05, 146MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [00:15<00:05, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 2.79G/3.50G [00:15<00:05, 138MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 2.81G/3.50G [00:15<00:05, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 2.83G/3.50G [00:15<00:04, 136MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████▏ | 2.85G/3.50G [00:15<00:05, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 2.87G/3.50G [00:15<00:04, 135MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 2.89G/3.50G [00:16<00:04, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 2.92G/3.50G [00:16<00:04, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 2.94G/3.50G [00:16<00:04, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 2.96G/3.50G [00:16<00:04, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 2.98G/3.50G [00:16<00:03, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.00G/3.50G [00:16<00:03, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▋ | 3.02G/3.50G [00:16<00:03, 131MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.04G/3.50G [00:17<00:03, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.06G/3.50G [00:17<00:04, 102MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▊ | 3.10G/3.50G [00:17<00:02, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 3.12G/3.50G [00:17<00:02, 136MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 3.15G/3.50G [00:17<00:02, 137MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 3.17G/3.50G [00:18<00:02, 135MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 3.19G/3.50G [00:18<00:02, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 3.21G/3.50G [00:18<00:02, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 3.23G/3.50G [00:18<00:02, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 3.25G/3.50G [00:18<00:01, 131MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 3.27G/3.50G [00:18<00:01, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 3.29G/3.50G [00:19<00:01, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 3.31G/3.50G [00:19<00:01, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 3.33G/3.50G [00:19<00:01, 130MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 3.36G/3.50G [00:19<00:01, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▋| 3.38G/3.50G [00:19<00:00, 135MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 3.41G/3.50G [00:19<00:00, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [00:19<00:00, 166MB/s]#033[A\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 3.46G/3.50G [00:20<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 3.49G/3.50G [00:20<00:00, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:20<00:00, 172MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:55<00:00, 26.50s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:55<00:00, 27.81s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.15s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.43s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.14s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 116/116 [00:00<00:00, 1.31MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 749/749 [00:00<00:00, 6.57MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 9.45MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 411/411 [00:00<00:00, 5.03MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mNo chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\u001b[0m\n",
      "\u001b[34mNo chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\u001b[0m\n",
      "\u001b[34mGenerating train split: 1 examples [00:00,  1.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 218 examples [00:01, 273.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 218 examples [00:01, 196.31 examples/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 0/162 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34m1%|          | 1/162 [00:18<50:17, 18.74s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 2/162 [00:36<49:07, 18.42s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/162 [00:55<48:32, 18.32s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 4/162 [01:13<48:06, 18.27s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 5/162 [01:31<47:44, 18.24s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 6/162 [01:49<47:23, 18.23s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 7/162 [02:07<47:03, 18.22s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 8/162 [02:26<46:44, 18.21s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 9/162 [02:44<46:26, 18.21s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 10/162 [03:02<46:07, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9257, 'grad_norm': 0.06005859375, 'learning_rate': 0.0002, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m6%|▌         | 10/162 [03:02<46:07, 18.21s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 11/162 [03:20<45:49, 18.21s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 12/162 [03:38<45:30, 18.21s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 13/162 [03:57<45:12, 18.21s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 14/162 [04:15<44:54, 18.20s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 15/162 [04:33<44:35, 18.20s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 16/162 [04:51<44:17, 18.20s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 17/162 [05:09<43:59, 18.20s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 18/162 [05:28<43:41, 18.20s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 19/162 [05:46<43:23, 18.21s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 20/162 [06:04<43:04, 18.20s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.743, 'grad_norm': 0.06640625, 'learning_rate': 0.0002, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 20/162 [06:04<43:04, 18.20s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 21/162 [06:22<42:46, 18.21s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 22/162 [06:40<42:28, 18.21s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 23/162 [06:59<42:10, 18.21s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 24/162 [07:17<41:52, 18.20s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 25/162 [07:35<41:33, 18.20s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 26/162 [07:53<41:15, 18.20s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 27/162 [08:11<40:57, 18.20s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 28/162 [08:30<40:39, 18.20s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 29/162 [08:48<40:21, 18.20s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 30/162 [09:06<40:02, 18.20s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.666, 'grad_norm': 0.087890625, 'learning_rate': 0.0002, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m19%|█▊        | 30/162 [09:06<40:02, 18.20s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 31/162 [09:24<39:44, 18.20s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 32/162 [09:43<39:26, 18.20s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 33/162 [10:01<39:08, 18.20s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 34/162 [10:19<38:50, 18.21s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 35/162 [10:37<38:32, 18.21s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 36/162 [10:55<38:14, 18.21s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 37/162 [11:14<37:55, 18.21s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 38/162 [11:32<37:39, 18.23s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 39/162 [11:50<37:21, 18.22s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 40/162 [12:08<37:02, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5866, 'grad_norm': 0.11083984375, 'learning_rate': 0.0002, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 40/162 [12:08<37:02, 18.21s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 41/162 [12:26<36:43, 18.21s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 42/162 [12:45<36:25, 18.21s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 43/162 [13:03<36:06, 18.21s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 44/162 [13:21<35:48, 18.20s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 45/162 [13:39<35:29, 18.20s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 46/162 [13:57<35:11, 18.20s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 47/162 [14:16<34:53, 18.20s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 48/162 [14:34<34:35, 18.20s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 49/162 [14:52<34:17, 18.21s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 50/162 [15:10<33:59, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5199, 'grad_norm': 0.06640625, 'learning_rate': 0.0002, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m31%|███       | 50/162 [15:10<33:59, 18.21s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 51/162 [15:28<33:40, 18.21s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 52/162 [15:47<33:22, 18.20s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 53/162 [16:05<33:04, 18.20s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 54/162 [16:23<32:46, 18.20s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 55/162 [16:42<32:43, 18.35s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 56/162 [17:00<32:19, 18.30s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 57/162 [17:18<31:58, 18.27s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 58/162 [17:36<31:37, 18.25s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 59/162 [17:55<31:17, 18.23s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 60/162 [18:13<30:58, 18.22s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4591, 'grad_norm': 0.076171875, 'learning_rate': 0.0002, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 60/162 [18:13<30:58, 18.22s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 61/162 [18:31<30:39, 18.22s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 62/162 [18:49<30:21, 18.21s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 63/162 [19:07<30:02, 18.21s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 64/162 [19:26<29:44, 18.21s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 65/162 [19:44<29:25, 18.20s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 66/162 [20:02<29:07, 18.21s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 67/162 [20:20<28:49, 18.21s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m42%|████▏     | 68/162 [20:38<28:31, 18.21s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 69/162 [20:57<28:13, 18.21s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 70/162 [21:15<27:55, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4308, 'grad_norm': 0.078125, 'learning_rate': 0.0002, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 70/162 [21:15<27:55, 18.21s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 71/162 [21:33<27:37, 18.21s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 72/162 [21:51<27:18, 18.21s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 73/162 [22:09<27:00, 18.21s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 74/162 [22:28<26:42, 18.21s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 75/162 [22:46<26:24, 18.21s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 76/162 [23:04<26:05, 18.21s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 77/162 [23:22<25:47, 18.21s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 78/162 [23:40<25:29, 18.20s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 79/162 [23:59<25:10, 18.20s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 80/162 [24:17<24:52, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.417, 'grad_norm': 0.091796875, 'learning_rate': 0.0002, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 80/162 [24:17<24:52, 18.21s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 81/162 [24:35<24:34, 18.21s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 82/162 [24:53<24:16, 18.21s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 83/162 [25:11<23:58, 18.21s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 84/162 [25:30<23:40, 18.21s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 85/162 [25:48<23:22, 18.21s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 86/162 [26:06<23:03, 18.21s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 87/162 [26:24<22:45, 18.21s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 88/162 [26:43<22:27, 18.21s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 89/162 [27:01<22:09, 18.21s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 90/162 [27:19<21:51, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3981, 'grad_norm': 0.103515625, 'learning_rate': 0.0002, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 90/162 [27:19<21:51, 18.21s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 91/162 [27:37<21:34, 18.23s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 92/162 [27:55<21:15, 18.22s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 93/162 [28:14<20:57, 18.22s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 94/162 [28:32<20:38, 18.22s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 95/162 [28:50<20:20, 18.22s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 96/162 [29:08<20:02, 18.22s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 97/162 [29:27<19:43, 18.21s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 98/162 [29:45<19:25, 18.21s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 99/162 [30:03<19:07, 18.21s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 100/162 [30:21<18:49, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.392, 'grad_norm': 0.10302734375, 'learning_rate': 0.0002, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 100/162 [30:21<18:49, 18.21s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 101/162 [30:39<18:30, 18.21s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 102/162 [30:58<18:12, 18.21s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 103/162 [31:16<17:54, 18.21s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 104/162 [31:34<17:36, 18.21s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 105/162 [31:52<17:17, 18.21s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 106/162 [32:10<16:59, 18.21s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 107/162 [32:29<16:41, 18.21s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 108/162 [32:47<16:23, 18.21s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 109/162 [33:05<16:05, 18.21s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 110/162 [33:24<15:55, 18.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3694, 'grad_norm': 0.115234375, 'learning_rate': 0.0002, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 110/162 [33:24<15:55, 18.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 111/162 [33:42<15:34, 18.33s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 112/162 [34:00<15:14, 18.29s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 113/162 [34:18<14:55, 18.27s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 114/162 [34:37<14:36, 18.25s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 115/162 [34:55<14:17, 18.24s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 116/162 [35:13<13:58, 18.23s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 117/162 [35:31<13:40, 18.22s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 118/162 [35:49<13:21, 18.22s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 119/162 [36:08<13:03, 18.22s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 120/162 [36:26<12:45, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3339, 'grad_norm': 0.11962890625, 'learning_rate': 0.0002, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 120/162 [36:26<12:45, 18.21s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 121/162 [36:44<12:26, 18.21s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 122/162 [37:02<12:08, 18.21s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 123/162 [37:21<11:50, 18.21s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 124/162 [37:39<11:32, 18.21s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 125/162 [37:57<11:13, 18.21s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 126/162 [38:15<10:55, 18.21s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 127/162 [38:33<10:37, 18.21s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 128/162 [38:52<10:19, 18.21s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 129/162 [39:10<10:00, 18.21s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 130/162 [39:28<09:42, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3286, 'grad_norm': 0.1298828125, 'learning_rate': 0.0002, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m80%|████████  | 130/162 [39:28<09:42, 18.21s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 131/162 [39:46<09:24, 18.21s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 132/162 [40:04<09:06, 18.21s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 133/162 [40:23<08:48, 18.21s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 134/162 [40:41<08:29, 18.21s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 135/162 [40:59<08:11, 18.21s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 136/162 [41:17<07:53, 18.21s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 137/162 [41:35<07:35, 18.21s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 138/162 [41:54<07:17, 18.21s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 139/162 [42:12<06:58, 18.21s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 140/162 [42:30<06:40, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3227, 'grad_norm': 0.12451171875, 'learning_rate': 0.0002, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 140/162 [42:30<06:40, 18.21s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 141/162 [42:48<06:22, 18.21s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 142/162 [43:07<06:04, 18.21s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 143/162 [43:25<05:45, 18.21s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 144/162 [43:43<05:27, 18.21s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 145/162 [44:01<05:09, 18.21s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 146/162 [44:19<04:51, 18.21s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 147/162 [44:38<04:33, 18.21s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 148/162 [44:56<04:14, 18.21s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 149/162 [45:14<03:56, 18.21s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 150/162 [45:32<03:38, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3149, 'grad_norm': 0.1376953125, 'learning_rate': 0.0002, 'epoch': 2.75}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 150/162 [45:32<03:38, 18.21s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 151/162 [45:50<03:20, 18.21s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 152/162 [46:09<03:02, 18.21s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 153/162 [46:27<02:43, 18.21s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 154/162 [46:45<02:25, 18.23s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 155/162 [47:03<02:07, 18.22s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 156/162 [47:21<01:49, 18.22s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 157/162 [47:40<01:31, 18.22s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 158/162 [47:58<01:12, 18.21s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 159/162 [48:16<00:54, 18.21s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 160/162 [48:34<00:36, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3155, 'grad_norm': 0.138671875, 'learning_rate': 0.0002, 'epoch': 2.94}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 160/162 [48:34<00:36, 18.21s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 161/162 [48:53<00:18, 18.21s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 162/162 [49:11<00:00, 18.21s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 2951.7487, 'train_samples_per_second': 0.222, 'train_steps_per_second': 0.055, 'train_loss': 0.4681900632970127, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m100%|██████████| 162/162 [49:11<00:00, 18.21s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 162/162 [49:11<00:00, 18.22s/it]\u001b[0m\n",
      "\u001b[34m['special_tokens_map.json', 'checkpoint-54', 'runs', 'adapter_config.json', 'adapter_model.safetensors', 'checkpoint-162', 'README.md', 'checkpoint-109', 'tokenizer.model', 'tokenizer.json', 'tokenizer_config.json']\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 14.83s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 15.76s/it]\u001b[0m\n",
      "\u001b[34m2024-03-29 18:33:30,349 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-29 18:33:30,349 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-29 18:33:30,349 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-29 18:35:08 Uploading - Uploading generated training model\n",
      "2024-03-29 18:35:08 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 3488\n",
      "Billable seconds: 3488\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6364a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-187605677219/codellama-7b-hf-text-to-sql-exp1-2024-03-29-17-35-24-810/output/model/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"].replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b90d46",
   "metadata": {},
   "source": [
    "# 4. Deploy & Evaluate LLM on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb5536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py310\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.4.0-gpu-py310-cu121-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.4.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873c5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d906ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-03-29-18-47-38-568\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2024-03-29-18-47-41-223\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2024-03-29-18-47-41-223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to give SageMaker the time to download the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35e7d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e63b14f1d84c99b7af3f86e24a5313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KIIT\\.cache\\huggingface\\hub\\models--codellama--CodeLlama-7b-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1052f1911664947951ff5a8e19ed50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb48849dd9b47ebb7a544ad20e44eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e68a1e07f94deabac853565ff44ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998642631ee24a519d8129f4b1a7e6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the CodeLlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'What are the names of all the circuits that are in the UK or Malaysia?', 'role': 'user'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'SELECT name FROM circuits WHERE country = \"UK\" OR country = \"Malaysia\"'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")\n",
    "\n",
    "# Load the test dataset from s3\n",
    "S3Downloader.download(f\"{training_input_path}/test_dataset.json\", \".\")\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\",split=\"train\")\n",
    "random_sample = test_dataset[345]\n",
    "\n",
    "def request(sample):\n",
    "    prompt = tokenizer.apply_chat_template(sample, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = llm.predict({\n",
    "      \"inputs\": prompt,\n",
    "      \"parameters\": {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"do_sample\": False,\n",
    "        \"return_full_text\": False,\n",
    "        \"stop\": [\"<|im_end|>\"],\n",
    "      }\n",
    "    })\n",
    "    return {\"role\": \"assistant\", \"content\": outputs[0][\"generated_text\"].strip()}\n",
    "\n",
    "print(random_sample[\"messages\"][1])\n",
    "request(random_sample[\"messages\"][:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e78255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(sample):\n",
    "    predicted_answer = request(sample[\"messages\"][:2])\n",
    "    if predicted_answer[\"content\"] == sample[\"messages\"][2][\"content\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "success_rate = []\n",
    "number_of_eval_samples = 1000\n",
    "# iterate over eval dataset and predict\n",
    "for s in tqdm(test_dataset.shuffle().select(range(number_of_eval_samples))):\n",
    "    success_rate.append(evaluate(s))\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = sum(success_rate)/len(success_rate)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53061c",
   "metadata": {},
   "source": [
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "042c69e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-tgi-inference-2024-03-29-18-47-38-568\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-tgi-inference-2024-03-29-18-47-41-223\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-tgi-inference-2024-03-29-18-47-41-223\n"
     ]
    }
   ],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf7fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
